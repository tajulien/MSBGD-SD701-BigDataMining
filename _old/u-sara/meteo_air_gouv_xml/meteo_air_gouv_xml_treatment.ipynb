{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ac0c2e",
   "metadata": {},
   "source": [
    "# Retraitement des données horaires de la qualité de l'air (format xml)\n",
    "\n",
    "#### Nous disposons de plusieurs datasets :\n",
    "\n",
    "- une collection de fichiers xml avec l'historique horaire de la qualité de l'air pour plusieurs région de France (1 fichier = 1 journée)\n",
    "- une base de donnée B\n",
    "- une base de donnée D\n",
    "\n",
    "L'objectif est de parser les différents fichiers xml pour obtenir un tableau clair des données, pour la région qui nous intéresse (Paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e08b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "#import ipdb\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import numpy as np\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3ce61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-b-lcsqa-ineris-20190724.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-d-lcsqa-ineris-20190918-1.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-d-v0.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-e2-2018-2018-09-12-04-t.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-e2-2018-2018-09-12-05-t.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-e2-2018-2018-09-17-14-t.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-e2-2018-2018-09-17-15-v.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-e2-2018-2018-09-17-16-v.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-e2-2018-2018-09-17-17-t.xml',\n",
       " 'https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2018/fr-2018-e2-2018-2018-09-17-18-v.xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Requête de tous les noms de fichier \n",
    "links=[]\n",
    "years = [2018,2019,2020,2021]\n",
    "for year in years:\n",
    "    \n",
    "    url_root = \"https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/\"+str(year)+\"/\"\n",
    "    r = requests.get(url_root)\n",
    "    soup_urls = BeautifulSoup(r.content,'xml')\n",
    "    soup_urls = soup_urls.find_all('a')[1:]\n",
    "    for url in soup_urls:\n",
    "        links.append(url_root+url.text)\n",
    "    \n",
    "    i=0\n",
    "    while i < len(links):\n",
    "    \n",
    "        \n",
    "        if links[i][:-6]==links[i-1][:-6]:\n",
    "            \n",
    "            #ipdb.set_trace()\n",
    "            if \"t\" in links[i][-5:]:\n",
    "                links.pop(i)\n",
    "            elif \"t\" in links[i-1][-5:]:\n",
    "                links.pop(i-1)\n",
    "            \n",
    "        i+=1\n",
    "print(len(links))\n",
    "links[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74181465",
   "metadata": {},
   "source": [
    "# Création du tableau de vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfc5be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code verification</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Preliminary verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Not verified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code verification           description\n",
       "0                  1              Verified\n",
       "1                  2  Preliminary verified\n",
       "2                  3          Not verified"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_verification = pd.DataFrame({'code verification':[1,2,3],'description':['Verified','Preliminary verified','Not verified']})\n",
    "tbl_verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2349a9d3",
   "metadata": {},
   "source": [
    "# Création du tableau de validité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d80ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code verification</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>Not valid due to station maintenance or calibr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Valid, but below detection limit measurement v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Valid, but below detection limit and number re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code verification                                        description\n",
       "0                -99  Not valid due to station maintenance or calibr...\n",
       "1                 -1                                          Not valid\n",
       "2                  1                                              Valid\n",
       "3                  2  Valid, but below detection limit measurement v...\n",
       "4                  3  Valid, but below detection limit and number re..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_validite = pd.DataFrame({'code verification':[-99,-1,1,2,3],\n",
    "                                 'description': ['Not valid due to station maintenance or calibration in the observationvalidity vocabulary',\n",
    "                                                 'Not valid',\n",
    "                                                 'Valid',\n",
    "                                                 'Valid, but below detection limit measurement value given in the observationvalidity vocabulary',\n",
    "                                                 'Valid, but below detection limit and number replaced by 0.5*detection limit in the observationvalidity vocabulary']})\n",
    "tbl_validite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2be626",
   "metadata": {},
   "source": [
    "# Récupération de la liste des polluants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef84e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Notation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sulphur dioxide (air)</td>\n",
       "      <td>SO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Strong acidity (air)</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Total suspended particulates (aerosol)</td>\n",
       "      <td>SPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Particulate matter &lt; 10 µm (aerosol)</td>\n",
       "      <td>PM10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code                                     Nom Notation\n",
       "0     1                   Sulphur dioxide (air)      SO2\n",
       "1     3                    Strong acidity (air)       SA\n",
       "2     4  Total suspended particulates (aerosol)      SPM\n",
       "3     5    Particulate matter < 10 µm (aerosol)     PM10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Récupération de la liste des polluants (ils ont préalablement été transposés depuis le site dans un fichier csv)\n",
    "#La liste est non exhaustive et comprend seulement les polluants qui sont mesurés dans le dataset\n",
    "tbl_polluants = pd.read_csv(\"polluants.csv\",sep=\";\")\n",
    "\n",
    "tbl_polluants.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b6586",
   "metadata": {},
   "source": [
    "# Récupération des données sur les points de prélèvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea3d884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfilename = \"D_points_prelevement.xml\"\\n#Attention, très lent\\nsoup_spots = BeautifulSoup(open(filename),\\'xml\\')\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "filename = \"D_points_prelevement.xml\"\n",
    "#Attention, très lent\n",
    "soup_spots = BeautifulSoup(open(filename),'xml')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e7959",
   "metadata": {},
   "source": [
    "Aperçu non exhaustif : \n",
    "    \n",
    "```xml\n",
    "  ...\n",
    "  <gml:featureMember>\n",
    "  ...\n",
    "  </gml:featureMember>\n",
    "  <gml:featureMember>\n",
    "  ...\n",
    "          <base:localId>SPO-FR01001_38</base:localId>\n",
    "            ...\n",
    "```\n",
    "<code style=\"background:yellow;color:black\">---> Code du point de prélèvement </code>\n",
    "```xml\n",
    "                   ...\n",
    "                    <gn:GeographicalName>\n",
    "                      ...\n",
    "                      <gn:spelling>\n",
    "                        <gn:SpellingOfName>\n",
    "                          <gn:text>SCHILTIGHEIM</gn:text>\n",
    "                        </gn:SpellingOfName>\n",
    "                      </gn:spelling>\n",
    "                    </gn:GeographicalName>\n",
    "                  </ad:adminUnit>\n",
    "                  <ad:locatorDesignator>5 rue de Madrid, Espace Européen de l'Entreprise</ad:locatorDesignator>\n",
    "                  <ad:postCode>67300</ad:postCode>\n",
    "               \n",
    "```\n",
    "<code style=\"background:yellow;color:black\">---> Ville + Département </code>\n",
    "```xml\n",
    "   ...\n",
    "  </gml:featureMember>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a707d1",
   "metadata": {},
   "source": [
    "Le dataset des villes n'est pas assez complet. Dans les csv de ce dossier : https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/temps-reel/2021/, les codes pour paris sont : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eebc843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PARIS1': 'FR04055',\n",
       " 'PARIS7': 'FR04060',\n",
       " 'PARIS12': 'FR04014',\n",
       " 'PARIS13': 'FR04037',\n",
       " 'PARIS18': 'FR04004'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_codes_paris = {'PARIS1':'FR04055' ,'PARIS7': 'FR04060', 'PARIS12': 'FR04014','PARIS13':'FR04037' ,'PARIS18':'FR04004'}\n",
    "dict_codes_paris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358c569",
   "metadata": {},
   "source": [
    "# Récupération et retraitement des data xml sur la qualité de l'air\n",
    "- https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2019/\n",
    "- https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2020/\n",
    "- https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/old/2021/\n",
    "\n",
    "#### Notes sur les différentes balises\n",
    "-----------------------------------------------\n",
    "```xml\n",
    "<gml:TimePeriod gml:id=\"REP_TP_FR_2018-12-31-23_E2\">\n",
    "<gml:beginPosition>2018-09-19T00:00:00Z</gml:beginPosition>\n",
    "<gml:endPosition>2018-10-10T00:00:00Z</gml:endPosition>\n",
    "</gml:TimePeriod>\n",
    "```\n",
    "Période sur laquelle s'étend la donnée dans tout le fichier.\n",
    "\n",
    "=================================================================================================\n",
    "\n",
    "```xml\n",
    "<aqd:content xlink:href=\"FR.LCSQA-INERIS.AQ/FR_OBS_et5tb64ner_FR070A_FR24040_7_1\"/>\n",
    "<aqd:content xlink:href=\"FR.LCSQA-INERIS.AQ/FR_OBS_86q294dv4i_FR070A_FR24039_5_2\"/>\n",
    "...\n",
    "```\n",
    "Points de prélèvement et polluants pour lesquelles les données sont fournies.\n",
    "\n",
    "FR070A_FR24040_7 : [code reseau mesure]_ [code station]_ [n° polluant]\n",
    "\n",
    "Numéros des polluants : http://dd.eionet.europa.eu/vocabulary/aq/pollutant/view?page=1#vocabularyConceptResults\n",
    "\n",
    "=================================================================================================\n",
    "```xml\n",
    "<om:parameter>\n",
    "<om:NamedValue>\n",
    "<om:name xlink:href=\"http://dd.eionet.europa.eu/vocabulary/aq/processparameter/SamplingPoint\"/>\n",
    "<om:value xlink:href=\"FR.LCSQA-INERIS.AQ/SPO-FR24040_7\"/> \n",
    "```\n",
    "<code style=\"background:yellow;color:black\">--- FR24040 : point de prélèvement</code>\n",
    "```xml\n",
    "</om:NamedValue>\n",
    "</om:parameter>\n",
    "<om:observedProperty xlink:href=\"http://dd.eionet.europa.eu/vocabulary/aq/pollutant/7\"/> \n",
    "``` \n",
    "<code style=\"background:yellow;color:black\">---> 7 : numéro de polluant</code>\n",
    "```xml\n",
    "<om:featureOfInterest xlink:href=\"FR.LCSQA-INERIS.AQ/SAM-FR24040_7\"/>\n",
    "<om:result>\n",
    "<swe:DataArray>\n",
    "<swe:elementCount>\n",
    "<swe:Count>\n",
    "<swe:value>24</swe:value>\n",
    "</swe:Count>\n",
    "</swe:elementCount>\n",
    "``` \n",
    "<code style=\"background:yellow;color:black\">---> 24 : nombre de données horaires disponibles sur la période de mesure</code>\n",
    "```xml\n",
    "\n",
    "<swe:elementType name=\"FixedObservations\">\n",
    "<swe:encoding>\n",
    "<swe:TextEncoding blockSeparator=\"@@\" decimalSeparator=\".\" tokenSeparator=\",\"/>\n",
    "</swe:encoding>\n",
    "<swe:values>2018-10-09T00:00:00+00:00,2018-10-09T01:00:00+00:00,2,1,61.0@@2018-10-09T01:00:00+00:00,2018-10-09T02:00:00+00:00,2,1,67.7@@2018-10-09T02:00:00+00:00,2018-10-09T03:00:00+00:00,2,1,65.0@@2018-10-09T03:00:00+00:00,2018-10-09T04:00:00+00:00,2,1,62.8@@2018-10-09T04:00:00+00:00,2018-10-09T05:00:00+00:00,2,1,66.5@@2018-10-09T05:00:00+00:00,2018-10-09T06:00:00+00:00,2,1,66.0@@</swe:values>\n",
    " ``` \n",
    "<code style=\"background:yellow;color:black\">---> Groupe de valeurs séparées par \"@@\" </code>\n",
    "    \n",
    "<code style=\"background:yellow;color:black\">2018-10-09T00:00:00+00:00,2018-10-09T01:00:00+00:00,2,1,61.0 = StartTime,EndTime,Verification (1), Validity (2), Value </code>\n",
    "\n",
    "(1) voir tbl_verification\n",
    "\n",
    "\n",
    "(2) voir tbl_validite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62152729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requête sur le code xml\n",
    "#r = requests.get(url_xml_test)\n",
    "#soup_data = BeautifulSoup(r.content,'xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b7782",
   "metadata": {},
   "source": [
    "Aperçu du résultat (non exhaustif) : \n",
    "    \n",
    "```xml\n",
    "...\n",
    "<gml:featureMember>\n",
    "...\n",
    "</gml:featureMember>\n",
    "<gml:featureMember>\n",
    "...\n",
    "<om:name xlink:href=\"http://dd.eionet.europa.eu/vocabulary/aq/processparameter/SamplingPoint\"/>\n",
    "<om:value xlink:href=\"FR.LCSQA-INERIS.AQ/SPO-FR24040_7\"/>\n",
    "...\n",
    "<swe:Count>\n",
    "<swe:value>24</swe:value>\n",
    "</swe:Count>\n",
    "...\n",
    "<swe:encoding>\n",
    "<swe:TextEncoding blockSeparator=\"@@\" decimalSeparator=\".\" tokenSeparator=\",\"/>\n",
    "</swe:encoding>\n",
    "<swe:values>2018-10-09T00:00:00+00:00,2018-10-09T01:00:00+00:00,2,1,79.7@@2018-10-09T01:00:00+00:00,2018-10-09T02:00:00+00:00,2,1,85.7@@2018-10-09T02:00:00+00:00,2018-10-09T03:00:00+00:00,2,1,77.8@@2018-10-09T03:00:00+00:00,2018-10-09T04:00:00+00:00,2,1,80.8@@2018-10-09T04:00:00+00:00,2018-10-09T05:00:00+00:00,2,1,77.8@@2018-10-09T05:00:00+00:00,2018-10-09T06:00:00+00:00,2,1,73.3@@</swe:values>\n",
    "...\n",
    "</gml:featureMember>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b876f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0% : working on -2018-e2-2018-2018-10-12-22-v.xml\n",
      "5.0% : working on -2018-e2-2018-2018-11-04-18-t.xml\n",
      "7.0% : working on -2018-e2-2018-2018-11-25-16-v.xml\n",
      "9.0% : working on -2018-e2-2018-2018-12-16-19-v.xml\n",
      "12.0% : working on -2019-e2-2019-2019-01-20-09-t.xml\n",
      "14.0% : working on -2019-e2-2019-2019-02-10-15-v.xml\n",
      "16.0% : working on -2019-e2-2019-2019-03-06-06-t.xml\n",
      "19.0% : working on -2019-e2-2019-2019-03-29-14-t.xml\n",
      "21.0% : working on -2019-e2-2019-2019-04-19-22-v.xml\n",
      "23.0% : working on -2019-e2-2019-2019-05-10-23-v.xml\n",
      "26.0% : working on -2019-e2-2019-2019-05-31-20-v.xml\n",
      "28.0% : working on -2019-e2-2019-2019-06-21-16-v.xml\n",
      "30.0% : working on -2019-e2-2019-2019-07-12-12-t.xml\n",
      "32.0% : working on -2019-e2-2019-2019-08-04-23-t.xml\n",
      "35.0% : working on -2019-e2-2019-2019-08-25-22-t.xml\n",
      "37.0% : working on -2019-e2-2019-2019-09-15-18-v.xml\n",
      "39.0% : working on -2019-e2-2019-2019-10-06-18-v.xml\n",
      "42.0% : working on -2019-e2-2019-2019-10-27-14-t.xml\n",
      "44.0% : working on -2019-e2-2019-2019-11-17-14-t.xml\n",
      "46.0% : working on -2019-e2-2019-2019-12-08-13-t.xml\n",
      "49.0% : working on -2019-e2-2019-2019-12-29-10-t.xml\n",
      "51.0% : working on -2020-e2-2019-2020-03-07-10-v.xml\n",
      "53.0% : working on -2020-e2-2020-2020-01-19-13-t.xml\n",
      "56.0% : working on -2020-e2-2020-2020-02-09-09-t.xml\n",
      "58.0% : working on -2020-e2-2020-2020-03-01-05-t.xml\n",
      "60.0% : working on -2020-e2-2020-2020-03-22-01-t.xml\n",
      "63.0% : working on -2020-e2-2020-2020-04-13-19-v.xml\n",
      "65.0% : working on -2020-e2-2020-2020-05-04-15-t.xml\n",
      "67.0% : working on -2020-e2-2020-2020-05-25-11-t.xml\n",
      "70.0% : working on -2020-e2-2020-2020-06-15-10-t.xml\n",
      "72.0% : working on -2020-e2-2020-2020-07-06-06-t.xml\n",
      "74.0% : working on -2020-e2-2020-2020-07-27-02-t.xml\n",
      "77.0% : working on -2020-e2-2020-2020-08-16-22-t.xml\n",
      "79.0% : working on -2020-e2-2020-2020-09-06-18-v.xml\n",
      "81.0% : working on -2020-e2-2020-2020-09-27-14-t.xml\n",
      "83.0% : working on -2020-e2-2020-2020-10-18-10-t.xml\n",
      "86.0% : working on -2020-e2-2020-2020-11-08-06-t.xml\n",
      "88.0% : working on -2020-e2-2020-2020-11-29-04-t.xml\n",
      "90.0% : working on -2020-e2-2020-2020-12-20-01-t.xml\n",
      "93.0% : working on -2021-e2-2021-2021-01-02-03-t.xml\n",
      "95.0% : working on -2021-e2-2021-2021-01-23-00-t.xml\n",
      "97.0% : working on -2021-e2-2021-2021-02-12-20-v.xml\n",
      "100.0% : working on -2021-e2-2021-2021-03-05-20-v.xml\n",
      "time 1 day, 3:09:51.962249\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>h début</th>\n",
       "      <th>h fin</th>\n",
       "      <th>codes_prelev</th>\n",
       "      <th>verif</th>\n",
       "      <th>valid</th>\n",
       "      <th>code_polluant</th>\n",
       "      <th>valeur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, h début, h fin, codes_prelev, verif, valid, code_polluant, valeur]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "dates = []\n",
    "h_debut = []\n",
    "h_fin = []\n",
    "codes_prelev = []\n",
    "verifs = []\n",
    "valid = []\n",
    "codes_pollu = []\n",
    "valeurs = []\n",
    "loop=0\n",
    "for url in links:\n",
    "    loop+=1\n",
    "    if loop%500==0:\n",
    "        print(str(np.round(loop/len(links)*100,0))+ '% : working on -' + url[100:])\n",
    "    \n",
    "    r = requests.get(url_xml_test)\n",
    "    soup_data = BeautifulSoup(r.content,'xml')\n",
    "    \n",
    "    all_xml_data = soup_data.find_all(\"gml:featureMember\")\n",
    "    \n",
    "    #Optimisation : on vérifie en amont s'il y a le code paris dans notre soupe\n",
    "    paris_in_soup = False\n",
    "    \n",
    "    str_soup = str(soup_data)\n",
    "    for code_paris in dict_codes_paris.values():\n",
    "        if code_paris in str_soup:\n",
    "            paris_in_soup = True\n",
    "            break\n",
    "        \n",
    "        for data in all_xml_data[1:]:\n",
    "            \n",
    "            #Récupération du code du point de prélèvement et du polluant \n",
    "            ref = str(data.find_all(\"om:value\")[1])\n",
    "            lst = ref.split('-')[-1].split(\"\\\"\")[0].split(\"_\")\n",
    "\n",
    "            code_zone_prelev = lst[0]\n",
    "\n",
    "            if code_zone_prelev in dict_codes_paris.values():\n",
    "                code_polluant = lst[1]\n",
    "\n",
    "\n",
    "                #if code_zone_prelev in dict_codes_paris.values():\n",
    "                #Récupération des données\n",
    "                values = data.find_all(\"swe:values\")[0].text\n",
    "                values_split = values.split('@@')[:-2]\n",
    "\n",
    "                for elem in values_split:\n",
    "                    elem = elem.split(\",\")\n",
    "\n",
    "                    dates.append(elem[0][:9])\n",
    "                    h_debut.append(elem[0])\n",
    "                    h_fin.append(elem[1])\n",
    "                    codes_prelev.append(code_zone_prelev)\n",
    "                    verifs.append(elem[2])\n",
    "                    valid.append(elem[3])\n",
    "                    codes_pollu.append(code_polluant)\n",
    "                    valeurs.append(elem[4])\n",
    "\n",
    "\n",
    "tbl_dataset = pd.DataFrame({\"date\":dates,\n",
    "                           \"h début\":h_debut,\n",
    "                            \"h fin\":h_fin,\n",
    "                            \"codes_prelev\":codes_prelev,\n",
    "                            \"verif\":verifs,\n",
    "                            \"valid\":valid,\n",
    "                            \"code_polluant\":codes_pollu,\n",
    "                            \"valeur\":valeurs,\n",
    "                           })\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(\"time\", (dt.datetime.now() - start_time))\n",
    "tbl_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d7c3c-cf5e-4564-ab44-82a6a5f4efba",
   "metadata": {},
   "source": [
    "Aucune donnée ne ressort pour Paris, bien que la documentation du dataset mentionnait Paris dans sa liste de points de prélèvements. Nous ne pouvions le savoir qu'en récupérant le contenu des 21 000 fichiers xml. Bien que le résultat soit quelque peu décevant, nous avons souhaité l'inclure à notre projet car il rend compte d'un aspect de la recherche de données : on peut passer un temps considérable à extraire les données d'un dataset sans garantie de résultat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
